Gordon D, Kembhavi A, Rastegari M, Redmon J, Fox D, Farhadi A  
CVPR2018  
[arXiv](https://arxiv.org/abs/1712.03316) , [pdf](https://arxiv.org/pdf/1712.03316.pdf) , [GitHub](https://github.com/danielgordon10/thor-iqa-cvpr-2018) , [YouTube](https://www.youtube.com/watch?v=pXd3C-1jr98&feature=youtu.be)

# どんなもの？
Interactive Question Answering (IQA)というタスクを提案．  
自律的エージェントの動的な視覚環境に関する質問に答えるタスク．  
![fig1]

# abstract
IQAはエージェントに場面と質問を提示します。 エージェントはシーンをナビゲートし、シーンの要素を視覚的に理解し、オブジェクトと対話し、質問に基づいて一連のアクションを計画する必要があります。 単一のコントローラーを使用した一般的な強化学習アプローチは、大きくて多様な状態空間のためにIQAでうまく機能しません。 我々は、システムが複数レベルの時間的抽象化で動作することを可能にする、コントローラの因数分解されたセットからなる階層型対話型メモリネットワーク（ＨＩＭＮ）を提案する。 HIMNを評価するために、インタラクティブオブジェクトを含む設定可能な屋内シーンのシミュレーションされた写実的な環境であるAI2-THOR [35]に基づいて構築された新しいデータセット、IQUAD V1を紹介します。 我々の実験は、我々の提案したモデルが、IQUAD V1上で人気のあるシングルコントローラベースの方法よりも優れていることを示しています。


